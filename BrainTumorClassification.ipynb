{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of BrainTumorClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PadmarajBhat/Machine-Learning/blob/master/BrainTumorClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTCyCln9DwLS",
        "colab_type": "text"
      },
      "source": [
        "# Detection of 3 Brain Tumors (Meningioma, Glioma and Pituitary) in T1-weighted contrast enhanced images\n",
        "\n",
        "### - Revisitng the Udacity Capstone Project in pursuit of better accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExaNYOAl3nSH",
        "colab_type": "text"
      },
      "source": [
        "# What is the problem statement?\n",
        "  * predict the tumor class given a MRI image\n",
        "  * OR predict the tumor class when both MRI and Tumor region is given !!!\n",
        "      * tumor region is identified and put in input dataset by experts\n",
        "          * can we have Image Segmentation problem ?\n",
        "\n",
        "\n",
        "  * I think this is the order of problem from easy level to difficult level\n",
        "    * Identify the tumor class from raw MRI image (here accuracy may be low)\n",
        "    * Identify the tumor class from raw MRI image with tumor region identified info (here accuracy may be better)\n",
        "    * Auto detect the tumor segment in a MRI image and classify the tumor (ideal application for a radiologist)\n",
        "\n",
        "    Let us try all the 3 !!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47aIRBi1lPdJ",
        "colab_type": "text"
      },
      "source": [
        "# Import Packages\n",
        "* read the input MRI images (.mat) files through ***h5py***\n",
        "* **bokeh** plot for the zoomed in analysis of a tumor and neighbors\n",
        "* ***pandas*** for data analysis and preprocessing\n",
        "* ***tensorflow*** for modelling and predicting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzYp6q2F5Doj",
        "colab_type": "code",
        "outputId": "f7aa159d-7a3b-4f13-cae7-e519f740efd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XamypXiCEdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from bokeh.io import output_notebook, show\n",
        "from bokeh.layouts import row\n",
        "from bokeh.plotting import figure\n",
        "output_notebook()\n",
        "\n",
        "import imageio\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import random # for radom selection from a list\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8abLHDC4ut4",
        "colab_type": "code",
        "outputId": "6d241075-e5f9-4c8a-94da-57d1619c49cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0-rc2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E7e82UO_cLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a Global variable\n",
        "tumor_names = [\"\",\"Meningioma\",\"Glioma\",\"Pituitary\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68mR7i5xla0f",
        "colab_type": "text"
      },
      "source": [
        "# Load Data\n",
        "\n",
        "* **Iteration 1**:\n",
        "    * Mount Google Drive\n",
        "    * Unzip it in colab disk\n",
        "    * load mat attributes to list of tuples ( with mri and tumor 5 point summary details)\n",
        "    * create a panda dataframe for analysis\n",
        "\n",
        "    ##### Issues Faced:\n",
        "    1. loading to panda with image took half(6GB) of RAM\n",
        "    * loading tumor along with mri image (as in mat file) crashed the colab\n",
        "      * Solution: let us load image but save only 5 point summary for both mri image and tumor\n",
        "\n",
        "    2. How do we scale/normalize the data?\n",
        "      * would tumor region have 0 in it ?\n",
        "        * only way to know is through the value present in the binary indicator == 1\n",
        "            * implementation through 2 for loops takes forever !!!\n",
        "              * need to implement throuhg np.where...a[a == 1] !!!\n",
        "            \n",
        "\n",
        "    3. Some images are less than 512\n",
        "        * pad the difference with 0s.\n",
        "        \n",
        "    4. Should tumor image be scaled between 0 -1? For now, brightness values are relative to that of the whole image to which it belongs to.\n",
        "\n",
        "    5. Epoch run failed due to no data generated by the custom generator.\n",
        "      * Going to try the ImageGenerator from the TF.\n",
        "\n",
        "\n",
        "* **Iteration 2** :\n",
        "  * ImageGenerator worked fine but the np to image conversion had used dtype of np.uint8 to avoid warning during saving to image. However, that lead to corrupt image and hence loss was more and accuracy was less.\n",
        "  * Generator built for the iteration is correct ?\n",
        "      * are *flips* is not damaging data\n",
        "\n",
        "* **Iteration 3** :\n",
        "  * validate the image augmentation in the ImageGenerator\n",
        "  * initial load the data was fine. zip based train and test failed\n",
        "\n",
        "* **Iteration 4**:\n",
        "  * open all mat(hdf5) files and load 5 point summary of mri and tumor to a panda df\n",
        "  * save all the numpy mri image array to training_data directory\n",
        "  * split the df to training : testing = 80 :20\n",
        "  * move the 20% of the testing to testing_data\n",
        "  * out of the 80% training data, move the 10% for the validation during training\n",
        "      * download\n",
        "        * 5\n",
        "        * b*.zip\n",
        "        * *.txt\n",
        "        * mat\n",
        "          * *.mat\n",
        "\n",
        "      * training_data\n",
        "        * 1\n",
        "          * *.npy\n",
        "        * 2\n",
        "          *  *.npy\n",
        "        * 3\n",
        "          * *.npy\n",
        "      * validation_data\n",
        "        * 1\n",
        "          * *.npy\n",
        "        * 2\n",
        "          *  *.npy\n",
        "        * 3\n",
        "          * *.npy\n",
        "      * testing_data\n",
        "        * 1\n",
        "          * *.npy\n",
        "        * 2\n",
        "          *  *.npy\n",
        "        * 3\n",
        "          * *.npy\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6trYXPZPJ54V",
        "colab_type": "text"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWr8OsJ1ar6P",
        "colab_type": "text"
      },
      "source": [
        "##### Google Drive File Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JiGOCo1vjPS",
        "colab_type": "code",
        "outputId": "5be39619-79d6-41d4-d909-ceb9394eca9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def loadMatFiles(dir=\"training_data/\"):\n",
        "  if not os.path.isfile(\"download/mat/1.mat\"):\n",
        "    cmds = [\n",
        "            \"rm -rf download data training_data testing_data\"\n",
        "            ,\"wget https://ndownloader.figshare.com/articles/1512427/versions/5 -P download\"\n",
        "            ,\"unzip download/5 -d download\"\n",
        "            ,\"unzip -q download/brainTumorDataPublic_1-766.zip -d download/mat\"\n",
        "            ,\"unzip -q download/brainTumorDataPublic_1533-2298.zip -d download/mat\"\n",
        "            ,\"unzip -q download/brainTumorDataPublic_767-1532.zip   -d download/mat\"\n",
        "            ,\"unzip -q download/brainTumorDataPublic_2299-3064.zip  -d download/mat\"]\n",
        "\n",
        "    for c in cmds:\n",
        "      os.system(c)\n",
        "  else:\n",
        "    print(\"mat files are loaded into download/mat directory\")\n",
        "\n",
        "def loadTraininData():\n",
        "  os.system(\"mkdir training_data training_data/1 training_data/2 training_data/3\")\n",
        "  if not len(os.listdir(\"training_data/1\")):\n",
        "    for file_name in os.listdir(\"download/mat\"):\n",
        "      with h5py.File(\"download/mat/\"+file_name,'r') as f:\n",
        "        mri_image = np.array(f['cjdata']['image'],dtype=np.int16)\n",
        "        label = np.array(f['cjdata']['label'], dtype=np.int)[0][0]\n",
        "        imageio.imwrite(\"training_data/\"+str(label)+\"/\"+file_name.split(\".\")[0]+'.jpg', mri_image)\n",
        "\n",
        "\n",
        "def loadTrainingData():\n",
        "  os.system(\"mkdir training_data training_data/1 training_data/2 training_data/3\")\n",
        "  if not len(os.listdir(\"training_data/1\")):\n",
        "    for file_name in os.listdir(\"download/mat\"):\n",
        "      with h5py.File(\"download/mat/\"+file_name,'r') as f:\n",
        "        mri_image = np.array(f['cjdata']['image'],dtype=np.int16)\n",
        "        label = np.array(f['cjdata']['label'], dtype=np.int)[0][0]\n",
        "        imageio.imwrite(\"training_data/\"+str(label)+\"/\"+file_name.split(\".\")[0]+'.jpg', mri_image)\n",
        "\n",
        "def loadTestingData():\n",
        "  os.system(\"mkdir testing_data testing_data/1 testing_data/2 testing_data/3\")\n",
        "  \n",
        "  for i in range(1,4):\n",
        "      if not len(os.listdir(\"testing_data/\"+str(i))):\n",
        "        files = os.listdir(\"training_data/\"+str(i))\n",
        "        for file in random.choices(files,k=round(len(files)*.2)):\n",
        "          try:\n",
        "            os.rename(\"training_data/\"+str(i)+\"/\"+file, \"testing_data/\"+str(i)+\"/\"+file)\n",
        "          except:\n",
        "            print(\"Ignoring \", file)\n",
        "\n",
        "def loadValidationData():\n",
        "  os.system(\"mkdir validation_data validation_data/1 validation_data/2 validation_data/3\")\n",
        "  \n",
        "  for i in range(1,4):\n",
        "      if not len(os.listdir(\"validation_data/\"+str(i))):\n",
        "        files = os.listdir(\"training_data/\"+str(i))\n",
        "        for file in random.choices(files,k=round(len(files)*.1)):\n",
        "          try:\n",
        "            os.rename(\"training_data/\"+str(i)+\"/\"+file, \"validation_data/\"+str(i)+\"/\"+file)\n",
        "          except:\n",
        "            print(\"Ignoring \", file)\n",
        "\n",
        "\n",
        "loadMatFiles()\n",
        "loadTrainingData()\n",
        "loadTestingData()\n",
        "loadValidationData()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mat files are loaded into download/mat directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyh_sPtY7UMy",
        "colab_type": "text"
      },
      "source": [
        "### Load Image Array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoGqScRpu7F5",
        "colab_type": "text"
      },
      "source": [
        "def retrieveImage(file_name):\n",
        "  f = h5py.File(file_name,'r')\n",
        "  mri_image = np.array(f['cjdata']['image'],dtype=np.float64)\n",
        "  if mri_image.shape[0] < 512:\n",
        "      print(\"Shape of the image : \", mri_image.shape)\n",
        "      mri_image = np.pad(mri_image,(512 - mri_image.shape[0])//2,'constant',constant_values=0)\n",
        "  return mri_image/mri_image.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II_gT4oC7bYb",
        "colab_type": "text"
      },
      "source": [
        "### Load Tumor Array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcPw_HqJ7pkX",
        "colab_type": "text"
      },
      "source": [
        "def retrieveTumorImage(file_name):\n",
        "  f = h5py.File(file_name,'r')\n",
        "  mri_image = np.array(f['cjdata']['tumorMask'],dtype=np.float128)\n",
        "  if mri_image.shape[0] < 512:\n",
        "      print(\"Shape of the image : \", mri_image.shape)\n",
        "      mri_image = np.pad(mri_image,(512 - mri_image.shape[0])//2,'constant',constant_values=0)\n",
        "  return mri_image/mri_image.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-c5y3LXGnCE",
        "colab_type": "text"
      },
      "source": [
        "### Create Directories for ImageGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry3jlMuXKdmD",
        "colab_type": "text"
      },
      "source": [
        "!mkdir \"training_data/images/\"\n",
        "!mkdir \"training_data/images/1\"\n",
        "!mkdir \"training_data/images/2\"\n",
        "!mkdir \"training_data/images/3\"\n",
        "\n",
        "!mkdir \"testing_data/images/\"\n",
        "!mkdir \"testing_data/images/1\"\n",
        "!mkdir \"testing_data/images/2\"\n",
        "!mkdir \"testing_data/images/3\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF_-ayUh7jlS",
        "colab_type": "text"
      },
      "source": [
        "### Load Image and Tumor Statistics to Panda\n",
        "\n",
        "*   Panda df would have 5 point summary of both mri and tumor\n",
        "*   data directory will have label wise subdirectories for ImageGenerator\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPUvYbhjEzet",
        "colab_type": "text"
      },
      "source": [
        "def return_imageInfo_from_mat_file(dir,file_name):\n",
        "    f = h5py.File(dir+file_name,'r')\n",
        "\n",
        "    mri_image = np.array(f['cjdata']['image'],dtype=np.float128)\n",
        "    #scaler = MinMaxScaler(feature_range=(1,2))\n",
        "    #mri_image = scaler.fit(mri_image)\n",
        "    mri_image = mri_image/mri_image.max()\n",
        "\n",
        "    if mri_image.shape[0] < 512:\n",
        "      print(\"Shape of the image : \", mri_image.shape)\n",
        "      mri_image = np.pad(mri_image,(512 - mri_image.shape[0])//2,'constant',constant_values=0)\n",
        "    \n",
        "    temp_mri_image = np.copy(mri_image)\n",
        "    temp_mri_image[temp_mri_image == 0 ] = 2\n",
        "\n",
        "    mri_quartiles = np.percentile(mri_image[mri_image > 0], [25, 50, 75,80,85,90,95,96,97,98,99])\n",
        "\n",
        "    tumor_image = np.array(f['cjdata']['tumorMask'], dtype=np.float128)\n",
        "    if tumor_image.shape[0] < 512:\n",
        "      print(\"Shape of the tumor image : \", tumor_image.shape)\n",
        "      tumor_image = np.pad(tumor_image,(512 - tumor_image.shape[0])//2,'constant',constant_values=0)\n",
        "    \n",
        "    tumor_image = temp_mri_image * tumor_image\n",
        "    tumor_image = tumor_image[tumor_image > 0]\n",
        "    tumor_image[tumor_image == 2] = 0\n",
        "\n",
        "    '''tumor_array =[]\n",
        "    for i in range(0,512):\n",
        "      for j in range(0,512):\n",
        "        if tumor_image[i][j]:\n",
        "          tumor_array.append(mri_image[i][j])\n",
        "\n",
        "    tumor_image = np.array(tumor_array, dtype=np.float)'''\n",
        "\n",
        "    tumor_quartiles = np.percentile(tumor_image, [25, 50, 75,80,85,90,95,96,97,98,99])\n",
        "\n",
        "    label=np.array(f['cjdata']['label'], dtype=np.int)[0][0]\n",
        "    imageio.imwrite(dir+\"images/\"+str(label)+\"/\"+file_name.split(\".\")[0]+'.jpg', np.array(f['cjdata']['image'],dtype=np.int16))\n",
        "\n",
        "    return np.array(f['cjdata']['PID'],dtype=np.int)[0][0] \\\n",
        "            ,mri_image.min() \\\n",
        "            ,mri_image.max() \\\n",
        "            ,mri_quartiles[0] \\\n",
        "            ,mri_quartiles[1] \\\n",
        "            ,mri_quartiles[2] \\\n",
        "            ,mri_quartiles[3] \\\n",
        "            ,mri_quartiles[4] \\\n",
        "            ,mri_quartiles[5] \\\n",
        "            ,mri_quartiles[6] \\\n",
        "            ,mri_quartiles[7] \\\n",
        "            ,mri_quartiles[8] \\\n",
        "            ,mri_quartiles[9] \\\n",
        "            ,mri_quartiles[10] \\\n",
        "            ,tumor_image.min() \\\n",
        "            ,tumor_image.max() \\\n",
        "            ,tumor_quartiles[0] \\\n",
        "            ,tumor_quartiles[1] \\\n",
        "            ,tumor_quartiles[2] \\\n",
        "            ,tumor_quartiles[3] \\\n",
        "            ,tumor_quartiles[4] \\\n",
        "            ,tumor_quartiles[5] \\\n",
        "            ,tumor_quartiles[6] \\\n",
        "            ,tumor_quartiles[7] \\\n",
        "            ,tumor_quartiles[8] \\\n",
        "            ,tumor_quartiles[9] \\\n",
        "            ,tumor_quartiles[10] \\\n",
        "            ,tumor_image.shape \\\n",
        "            ,file_name\\\n",
        "            ,np.array(f['cjdata']['label'], dtype=np.int)[0][0] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h9X8MvPNy50",
        "colab_type": "text"
      },
      "source": [
        "def loadDf(dir=\"training_data/\"):\n",
        "  patients_details = []\n",
        "  '''for root, dirs, files in os.walk(\"/content/drive/My Drive/1512427/\", topdown = False):\n",
        "    for f in files:\n",
        "      if \".zip\" in f:\n",
        "          file = zipfile.ZipFile(root+f, \"r\")\n",
        "          for name in file.namelist():\n",
        "            file.extract(name,\".\")\n",
        "            patients_details.append(return_imageInfo_from_mat_file(name))\n",
        "          #break\n",
        "      #break  '''   \n",
        "  \n",
        "  for f in getFileNames(dir):\n",
        "    if \".mat\" in f:\n",
        "      patients_details.append(return_imageInfo_from_mat_file(dir,f))\n",
        "  mri_col_names = [\"mri_min\",\"mri_max\",\"mri_1q\",\"mri_median\", \"mri_3q\",\"mri_80\",\"mri_85\",\"mri_90\",\"mri_95\",\"mri_96\",\"mri_97\",\"mri_98\",\"mri_99\"]\n",
        "  tumor_col_names = [\"t_min\",\"t_max\",\"t_1q\",\"t_median\",\"t_3q\",\"t_80\",\"t_85\",\"t_90\",\"t_95\",\"t_96\",\"t_97\",\"t_98\",\"t_99\",\"tumor_size\"]\n",
        "  col_names = [\"pid\"] + mri_col_names + tumor_col_names+ [\"file_name\",\"label\"]\n",
        "  return pd.DataFrame(patients_details,columns=col_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ooal44AcufXG",
        "colab_type": "text"
      },
      "source": [
        "### Load Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCSo34a4Vlta",
        "colab_type": "text"
      },
      "source": [
        "df = loadDf()\n",
        "df[\"square_shape\"] = df.tumor_size.apply(lambda x: np.sqrt(x[0]))\n",
        "df.sample(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-G7l5uvulcY",
        "colab_type": "text"
      },
      "source": [
        "### Load Testing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upUrUpLMunt1",
        "colab_type": "text"
      },
      "source": [
        "df_test = loadDf(\"testing_data/\")\n",
        "df_test[\"square_shape\"] = df_test.tumor_size.apply(lambda x: np.sqrt(x[0]))\n",
        "df_test.sample(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCGj95Q6u1eC",
        "colab_type": "text"
      },
      "source": [
        "### Test the loaded data (both Training and Testing Data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBtoXDYUu7Zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def displayNpImages(dir=\"training_data/\"):\n",
        "  for i in range(1,4):\n",
        "    print(\"2 samples for \",tumor_names[i])\n",
        "    for j in random.choices( os.listdir(dir+str(i)),k=2):\n",
        "      plt.imshow(plt.imread(dir+str(i)+\"/\"+str(j)))\n",
        "      plt.show()\n",
        "\n",
        "#displayNpImages()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udE3comcx3Oe",
        "colab_type": "text"
      },
      "source": [
        "#### Visual Testing Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APHWSr83x8mO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#displayNpImages(\"testing_data/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJc8C31m9Efe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#displayNpImages(\"validation_data/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeU2lq6Lzb_-",
        "colab_type": "text"
      },
      "source": [
        "def analyzeZipDir(df,start,end):\n",
        "  df[\"file_num\"] = df.file_name.apply(lambda x: x.split(\".\")[0])\n",
        "  df[\"file_num\"] = df.file_num.astype(np.int)\n",
        "  \n",
        "  return df[df.file_num.isin(list(range(start,end)))]\n",
        "analyzeZipDir(df.copy(),1,766).groupby(\"label\").agg(\"count\").reset_index()[[\"label\",\"pid\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UnHytYu1RhE",
        "colab_type": "text"
      },
      "source": [
        "analyzeZipDir(df.copy(),1533,2298).groupby(\"label\").agg(\"count\").reset_index()[[\"label\",\"pid\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0By0gpPh1W8R",
        "colab_type": "text"
      },
      "source": [
        "analyzeZipDir(df_test.copy(),2299,3064).groupby(\"label\").agg(\"count\").reset_index()[[\"label\",\"pid\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHedgA0R2cy9",
        "colab_type": "text"
      },
      "source": [
        "analyzeZipDir(df.copy(),767,1532).groupby(\"label\").agg(\"count\").reset_index()[[\"label\",\"pid\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI-XfW7wbi2n",
        "colab_type": "text"
      },
      "source": [
        "### Create Test directory for validation through generators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrpZ1DnxSFdz",
        "colab_type": "text"
      },
      "source": [
        "!rm -rf \"test\"\n",
        "!mkdir \"test\"\n",
        "!mkdir \"test/1\"\n",
        "!mkdir \"test/2\"\n",
        "!mkdir \"test/3\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkPpIuurTUKt",
        "colab_type": "text"
      },
      "source": [
        "!ls -l /content/data/2/3046.jpg\n",
        "!ls -l /content/test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhVfTlhdXtG-",
        "colab_type": "text"
      },
      "source": [
        "!ls -l /content/data/2/2404.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GLeYdm-cWAU",
        "colab_type": "text"
      },
      "source": [
        "### Move the test set to test directory from data directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMyBzfxxP07c",
        "colab_type": "text"
      },
      "source": [
        "import shutil\n",
        "import random\n",
        "\n",
        "for root, dirs, files in os.walk(\"/content/data\", topdown = False):\n",
        "  \n",
        "    \n",
        "    if len(files) > 0:\n",
        "      print(root, dirs, files)\n",
        "\n",
        "      #indices = np.random.randint(0,len(files),size=round(len(files)*.2))\n",
        "      rand_files = random.choices(files,k=round(len(files)*.2))\n",
        "      \n",
        "      for f in rand_files:\n",
        "        #print(f)\n",
        "        try:\n",
        "          shutil.move(root+\"/\"+f, \"/content/test/\"+root.split(\"/\")[-1]+\"/\"+f)\n",
        "        except :\n",
        "          print(\"Ignoring : \",f)\n",
        "\n",
        "#list(os.walk(\"/content/data\")) /content/test /content/training_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-eDxHYafKUK",
        "colab_type": "text"
      },
      "source": [
        "### ImageGenerators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaUsWtDlGsfB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "c76d10d3-4e94-4c5b-ab9a-0df6341a7d33"
      },
      "source": [
        "def getGenerators(batch_size, image_size):\n",
        "  train_datagen = ImageDataGenerator(\n",
        "          #samplewise_std_normalization=True\n",
        "          horizontal_flip=True\n",
        "          ,rescale=1/255\n",
        "          ,vertical_flip= True)\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "          '/content/training_data',\n",
        "          target_size=image_size,\n",
        "          batch_size=batch_size,\n",
        "          class_mode='categorical')\n",
        "\n",
        "  validate_datagen = ImageDataGenerator(rescale=1/255)\n",
        "  validate_generator = validate_datagen.flow_from_directory(\n",
        "          '/content/validation_data',\n",
        "          target_size=image_size,\n",
        "          batch_size=batch_size,\n",
        "          class_mode='categorical')\n",
        "\n",
        "  test_datagen = ImageDataGenerator(rescale=1/255)\n",
        "  test_generator = test_datagen.flow_from_directory(\n",
        "          '/content/testing_data',\n",
        "          target_size=image_size,\n",
        "          batch_size=batch_size,\n",
        "          class_mode='categorical')\n",
        "  \n",
        "  return train_generator, validate_generator, test_generator\n",
        "\n",
        "train_generator, validate_generator, test_generator = getGenerators(32,(512,512))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2269 images belonging to 3 classes.\n",
            "Found 235 images belonging to 3 classes.\n",
            "Found 560 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pyYghx5gdCe",
        "colab_type": "text"
      },
      "source": [
        "### Load tf.data\n",
        "* inspired from: https://stackoverflow.com/questions/48309631/tensorflow-tf-data-dataset-reading-large-hdf5-files\n",
        "* extract all files\n",
        "* save file names in a tensor\n",
        "* write a generator function to read a file and return numpy mri image array and its label\n",
        "* using tf.dataset.interleave function, read the file concurrently\n",
        "* apply batch and shuffle\n",
        "* feed it to model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77irdWdhtaxN",
        "colab_type": "text"
      },
      "source": [
        "##### Download the MRI image zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgd4_g2h7rYa",
        "colab_type": "text"
      },
      "source": [
        "def mygenerator(file_name, dir=\"training_data/\"):\n",
        "  #print(file_name)\n",
        "  f = h5py.File(dir+file_name,'r')\n",
        "  #print(f['cjdata']['image'].dtype)\n",
        "  mri_image = np.array(f['cjdata']['image'],dtype=np.int16)\n",
        "  if mri_image.shape[0] < 512:\n",
        "      #print(\"Shape of the image : \", mri_image.shape)\n",
        "      mri_image = np.pad(mri_image,(512 - mri_image.shape[0])//2,'constant',constant_values=0)\n",
        "  return (mri_image, np.array(f['cjdata']['label'], dtype=np.int)[0][0])\n",
        "\n",
        "\n",
        "df_temp = pd.DataFrame([mygenerator(f) for f in getFileNames()],columns=[\"image\",\"label\"])\n",
        "\n",
        "'''ds = tf.data.Dataset.from_tensor_slices([  tf.data.Dataset.from_generator(\n",
        "        mygenerator(filename), \n",
        "        (tf.uint8,tf.int8), \n",
        "        (tf.TensorShape([]), tf.TensorShape([None]))) for filename in ds])'''\n",
        "df_temp.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX4-RohAP6hK",
        "colab_type": "text"
      },
      "source": [
        "imageio.imwrite(\"test.jpg\",df_temp.iloc[0][0])\n",
        "plt.imshow(imageio.imread(\"test.jpg\"),cmap='bone')\n",
        "plt.show()\n",
        "plt.imshow(plt.imread(\"test.jpg\"))\n",
        "plt.show()\n",
        "plt.imshow(df_temp.iloc[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgjK1-K4N8Ue",
        "colab_type": "text"
      },
      "source": [
        "plt.imshow(np.array(df_temp.iloc[0][0],dtype=np.uint8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLreCMdqiiAq",
        "colab_type": "text"
      },
      "source": [
        "class ToTensor:\n",
        "  def __init__(self):\n",
        "    print(\"Obj Created\")\n",
        "  \n",
        "  def unzipData(self,source_dirname, dest_dir=\"data/\"):\n",
        "    try:\n",
        "      shutil.rmtree(dest_dir)\n",
        "    except:\n",
        "      pass\n",
        "    os.mkdir(dest_dir)\n",
        "    print(\"Exploring \",source_dirname, \"directory\")\n",
        "    for root, dirs, files in os.walk(source_dirname, topdown = False):\n",
        "      for f in files:\n",
        "        print(\"Found file \",f)\n",
        "        if \".zip\" in f:\n",
        "          print(\"Unzipping \", f)\n",
        "          with zipfile.ZipFile(f) as zf:\n",
        "            zf.extractall(dest_dir)\n",
        "    print(\"Files Loaded !!!\")\n",
        "    return self\n",
        "\n",
        "  def getFileName(self,dir_name=\"data/\"):\n",
        "    return os.listdir(dir_name)\n",
        "\n",
        "toTensor = ToTensor()\n",
        "toTensor.unzipData(\"/content/drive/My Drive/1512427/\").getFileName()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0KYEepMovPx",
        "colab_type": "text"
      },
      "source": [
        "# Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tqRGoUK5APW",
        "colab_type": "text"
      },
      "source": [
        "## Statistical Analysis\n",
        "* Number of patients in the dataset\n",
        "* Patient wise distribution of tumor classes\n",
        "* Comparison of below attributes for the 3 tumor classes\n",
        "  * 1st quantile of MRI image\n",
        "  * Median of the MRI image\n",
        "  * 3rd quantile of the MRI image\n",
        "  * min value distribution of the Tumor\n",
        "  * max value distribution of the Tumor\n",
        "  * 1st quantile of the Tumor\n",
        "  * median of the Tumor\n",
        "  * 3rd quantile of the Tumor\n",
        "    * Analysis: \n",
        "      * All tumors have darkest area which may indicate the tumor itself\n",
        "      * All tumors have uniform distribution of brightness (apart from the dark area)\n",
        "      * MRI images have darker area outside the skull (non scan area)\n",
        "          * will this influence the model ?\n",
        "          * should the color of the tumor and the non important area of the MRI scan be different ?\n",
        "          \n",
        "* 256x256 image size distribution (any bias in there ?)\n",
        "\n",
        "##### Issues Faced:\n",
        "* Bokeh plots are interactive but they consume a lot of space(>100mb) in the notebook \n",
        "  * markdown for now, when interested can be seen by enabling it as code cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aumAqfm3VymM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "a9abfcf0-3d3d-42dd-9210-057450109845"
      },
      "source": [
        "df.pid.unique()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-8b8a792ab500>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXwJqH_jnfor",
        "colab_type": "text"
      },
      "source": [
        "There are only 5 patients info present !!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvBti1CInkCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.groupby(\"pid\").agg(\"count\").reset_index()[['pid','mri_min']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d-95548oIsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.groupby([\"pid\",\"label\"]).agg(\"count\").reset_index()[['pid','label','mri_min']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z0gzrC-qPjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.groupby(\"label\").agg(\"count\").reset_index()[['label','pid']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCCP1RnBrn2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotStatistics(df, tumor_name):\n",
        "  df = df[[\"mri_1q\",\"mri_median\",\"mri_3q\",\"t_min\",\"t_1q\",\"t_median\",\"t_3q\",\"t_max\"]]\n",
        "  df=(df-df.min())/(df.max()-df.min())\n",
        "  fig, ax = plt.subplots(1, 8,sharex=True,sharey=True,tight_layout=True)\n",
        "  fig.set_figheight(4)\n",
        "  fig.set_figwidth(13)\n",
        "  \n",
        "  fig.suptitle(tumor_name+\" Tumor\")\n",
        "  #plt.subplot(1,8,1)\n",
        "  ax[0].hist(df.mri_1q.tolist())\n",
        "  ax[0].set_title(\"mri_1q\")\n",
        "  #plt.subplot(1,8,2)\n",
        "  ax[1].hist(df.mri_median.tolist())\n",
        "  ax[1].set_title(\"mri_median\")\n",
        "  #plt.subplot(1,8,3)\n",
        "  ax[2].hist(df.mri_3q.tolist())\n",
        "  ax[2].set_title(\"mri_3q\")\n",
        "  #plt.subplot(1,8,4)\n",
        "  ax[3].hist(df.t_min.tolist())\n",
        "  ax[3].set_title(\"t_min\")\n",
        "  #plt.subplot(1,8,5)\n",
        "  ax[4].hist(df.t_1q.tolist())\n",
        "  ax[4].set_title(\"t_1q\")\n",
        "  #plt.subplot(1,8,6)\n",
        "  ax[5].hist(df.t_median.tolist())\n",
        "  ax[5].set_title(\"t_median\")\n",
        "  #plt.subplot(1,8,7)\n",
        "  ax[6].hist(df.t_3q.tolist())\n",
        "  ax[6].set_title(\"t_3q\")\n",
        "  #plt.subplot(1,8,8)\n",
        "  ax[7].hist(df.t_max.tolist())\n",
        "  ax[7].set_title(\"t_max\")\n",
        "  plt.show()\n",
        "\n",
        "plotStatistics(df[df.label ==1], tumor_names[1])\n",
        "plotStatistics(df[df.label ==2], tumor_names[2])\n",
        "plotStatistics(df[df.label ==3], tumor_names[3])\n",
        "plotStatistics(df, \"All\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW6obIAoho0m",
        "colab_type": "text"
      },
      "source": [
        "## Can we reduce the image size ?\n",
        "* Why?\n",
        "  * faster model building\n",
        "  * lower convolution experiment iterations\n",
        "  * lower ram usage and hence higher batch size\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQYMkEwLlfPv",
        "colab_type": "text"
      },
      "source": [
        "### Approach 1 : Can we segregate the skull ?\n",
        "  * removing the unwanted area \n",
        "    * percentile approach: identify the percentile and see if any of the tumor percentile is always less that the MRI percentile. \n",
        "        i.e. to prove mri_99 > t_99. This failed as indicated below\n",
        "    * brightness based skull identification:\n",
        "      * nearest neighbor ???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H8qcdkeIFyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[df.mri_99 < df.t_99]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAI0eeqfjUZi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(retrieveImage(\"120.mat\"))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCNwwdLSoLjt",
        "colab_type": "text"
      },
      "source": [
        "### Approach 2: PCA\n",
        "* Note that if we do the PCA transformation, we 2D image will be reduced to 1D. Therefore, we can not use it for the Convolution approach.\n",
        "  * we can note here that just by 2 features (components) and the trained PCA model, we are able to recreate the image with not much difference. [See the last 3 images] This showcases the PCA strength.\n",
        "\n",
        "* Withhelding the PCA approach as we are going to pursuit the Convolution \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOkU29MBoSzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=5,whiten=True)\n",
        "image=[]\n",
        "image.append(retrieveImage(\"120.mat\").reshape(-1))\n",
        "image.append(retrieveImage(\"1.mat\").reshape(-1))\n",
        "image.append(retrieveImage(\"2.mat\").reshape(-1))\n",
        "image.append(retrieveImage(\"3.mat\").reshape(-1))\n",
        "image.append(retrieveImage(\"4.mat\").reshape(-1))\n",
        "image.append(retrieveImage(\"5.mat\").reshape(-1))\n",
        "image.append(retrieveImage(\"6.mat\").reshape(-1))\n",
        "image.append(retrieveImage(\"7.mat\").reshape(-1))\n",
        "\n",
        "#print(image.shape)\n",
        "\n",
        "pca.fit(image)\n",
        "plt.imshow(pca.mean_.reshape((512,512)),\n",
        "           cmap=plt.cm.bone)\n",
        "plt.show()\n",
        "\n",
        "print(pca.noise_variance_)\n",
        "print(image[0].reshape((1,-1)).shape)\n",
        "pca.transform(image[0].reshape((1,-1)))\n",
        "\n",
        "#plt.imshow(pca.transform(image[1].reshape(1,-1)).reshape((512,512)),cmap=plt.cm.bone)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ptnmf6M4Phe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "components = pca.transform(image[0].reshape(1,-1))\n",
        "projected = pca.inverse_transform(components)\n",
        "plt.imshow(projected.reshape((512,512)))\n",
        "plt.show()\n",
        "plt.imshow(image[0].reshape((512,512)))\n",
        "plt.show()\n",
        "plt.imshow(retrieveImage(\"120.mat\"))\n",
        "plt.show()\n",
        "print(\"doe it match :\", projected.reshape((512,512)) == retrieveImage(\"120.mat\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmKL2wU4eHoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(image[0].reshape((256,256)))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NZjperm5HpZ",
        "colab_type": "text"
      },
      "source": [
        "## Visual Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYCnbIgH360L",
        "colab_type": "text"
      },
      "source": [
        "### Smallest Tumor Sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH9v4orNwTFk",
        "colab_type": "text"
      },
      "source": [
        "plt.imshow(retrieveImage(list(df[df.tumor_size == df.tumor_size.min()]['file_name'])[0]));\n",
        "plt.imshow(retrieveTumorImage(list(df[df.tumor_size == df.tumor_size.min()]['file_name'])[0]),alpha=0.5);\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj_utuj44fUp",
        "colab_type": "text"
      },
      "source": [
        "### Biggest Tumor in the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0btsuHfkxfty",
        "colab_type": "text"
      },
      "source": [
        "plt.imshow(retrieveImage(list(df[df.tumor_size == df.tumor_size.max()]['file_name'])[0]));\n",
        "plt.imshow(retrieveTumorImage(list(df[df.tumor_size == df.tumor_size.max()]['file_name'])[0]),alpha=0.5);\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6Jgv6oj30uI",
        "colab_type": "text"
      },
      "source": [
        "### Numpy Resize failed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aYJNq38zCRL",
        "colab_type": "text"
      },
      "source": [
        "plt.imshow(np.resize(retrieveImage(list(df[df.tumor_size == df.tumor_size.max()]['file_name'])[0]),(256,256)));\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJy0WXR3A_Td",
        "colab_type": "text"
      },
      "source": [
        "### Bokeh Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqrwFc48BCh9",
        "colab_type": "text"
      },
      "source": [
        "def bokehPlot(file_name, tumor_label):\n",
        "  tumor_names = [\"\",\"Meningioma\",\"Glioma\",\"Pituitary\"]\n",
        "  im = retrieveImage(file_name)\n",
        "  s1 = figure(width=512, plot_height=512, title=tumor_names[tumor_label]+\" MRI Image\")\n",
        "  s1.image([im],x=[0],y=[0],dw=[512],dh=[512])\n",
        "\n",
        "  im2 = retrieveTumorImage(file_name)\n",
        "\n",
        "  s2 = figure(width=500, plot_height=500, title=tumor_names[tumor_label]+\" MRI Image with Tumor Highlighted\")\n",
        "  s2.image([im2],x=[0],y=[0],dw=[512],dh=[512])\n",
        "  s2.image([im],x=[0],y=[0],dw=[512],dh=[512],global_alpha=0.5)\n",
        "\n",
        "  show(row(s1,s2))\n",
        "\n",
        "bokehPlot(list(df[df.tumor_size == df.tumor_size.max()]['file_name'])[0], list(df[df.tumor_size == df.tumor_size.max()]['label'])[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ0e1zAWWE4l",
        "colab_type": "text"
      },
      "source": [
        "#### Meningioma Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9dliKZMWINQ",
        "colab_type": "text"
      },
      "source": [
        "for fname in list(df[df.label == 1].sample(3)[\"file_name\"]):\n",
        "  bokehPlot(fname,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pP6euXXWqpU",
        "colab_type": "text"
      },
      "source": [
        "#### Glioma Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22qcn6KiWvMJ",
        "colab_type": "text"
      },
      "source": [
        "for fname in list(df[df.label == 2].sample(3)[\"file_name\"]):\n",
        "  bokehPlot(fname,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_3qNVQqV9A8",
        "colab_type": "text"
      },
      "source": [
        "#### Pituitary Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8P5A-cQO79W",
        "colab_type": "text"
      },
      "source": [
        "for fname in list(df[df.label == 3].sample(3)[\"file_name\"]):\n",
        "  bokehPlot(fname,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RdvYCpyo2vC",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6QgmzMKv6Hw",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing ideas:\n",
        "\n",
        "1.  Dataset has tumor region indicator which would allow us to get the average brightness of the area.\n",
        "\n",
        "2. It is said that brightest region is skull and skull is not important for the tumor detection. It is only brain position determines the tumor class. If we remove skull remaining image is brain ?\n",
        "\n",
        "3. if we start with a window of image which would maximize the presence of tumor and expand to include some brain region around the tumor then i guess it is the best data for training(and predicting). Because tumor position in brain is THE factor that decides the tumor class.\n",
        "\n",
        "4. what is the optimum batch size for training?\n",
        "\n",
        "5. what is the overall Image augumented training dataset size ?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDE9zmipLimp",
        "colab_type": "text"
      },
      "source": [
        "## Train & Test split\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dA-tbvOLt9b",
        "colab_type": "text"
      },
      "source": [
        "def getSplit(df):\n",
        "  df_test=df.sample(frac=.2)\n",
        "  df = df.drop(df_test.index)\n",
        "  return df, df_test\n",
        "\n",
        "df_orig = df.copy()\n",
        "df,df_test = getSplit(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGWNu-Zpk04v",
        "colab_type": "text"
      },
      "source": [
        "## Batch Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvedxzrclan5",
        "colab_type": "text"
      },
      "source": [
        "df.groupby(\"label\").agg(\"count\").reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d81fcRggmMy5",
        "colab_type": "text"
      },
      "source": [
        "def returnBatchIndices(df,batch_size):\n",
        "  label_1 = df[df.label == 1].index.tolist()\n",
        "  label_2 = df[df.label == 2].index.tolist()\n",
        "  label_3 = df[df.label == 3].index.tolist()\n",
        "\n",
        "  label_list = []\n",
        "  #print(len(label_1), len(label_2),len(label_3),list(range(0,max(len(label_1),len(label_2),len(label_3)),batch_size)))\n",
        "  for i in range(0,max(len(label_1),len(label_2),len(label_3)),batch_size):\n",
        "    label_list.append(label_1[i:i+batch_size] + label_2[i:i+batch_size] + label_3[i:i+batch_size])\n",
        "  return label_list\n",
        "\n",
        "#yieldbatch(df,5)\n",
        "for batch in returnBatchIndices(df,5):\n",
        "  print(batch)\n",
        "  break\n",
        "\n",
        "print(\"Total Number of Batches: \", len(returnBatchIndices(df,5)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk60VHloMRo3",
        "colab_type": "text"
      },
      "source": [
        "### For Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kexzUUlVk3pi",
        "colab_type": "text"
      },
      "source": [
        "def returnABatch(df,batch_size):\n",
        "  #returns a balanced label mri images\n",
        "  index_list = returnBatchIndices(df,batch_size)\n",
        "  #print(\"index list\",len(list(index_list)))\n",
        "  df2 = pd.get_dummies(df['label'], prefix = 'label')\n",
        "  df = pd.concat([df,df2],axis=1)\n",
        "  for j in index_list:\n",
        "    batch_images=[]\n",
        "    batch_labels=[]\n",
        "    #print(\"j\",j)\n",
        "    for i in j:\n",
        "      #print(\"i\",i)\n",
        "      label_list=[]\n",
        "      image = retrieveImage(list(df[df.index == i]['file_name'])[0])\n",
        "      transformed_image = image.reshape((512,512,1))\n",
        "      batch_images.append(transformed_image)\n",
        "      label_list.append(df[df.index == i]['label_1'].tolist()[0])\n",
        "      label_list.append(df[df.index == i]['label_2'].tolist()[0])\n",
        "      label_list.append(df[df.index == i]['label_3'].tolist()[0])\n",
        "      batch_labels.append(label_list)\n",
        "      #print(\"Batches :\",len(batch_images),len(batch_labels))\n",
        "\n",
        "    #from keras.utils import to_categorical\n",
        "    #batch_labels = to_categorical(batch_labels)\n",
        "    yield np.array(batch_images), np.array(batch_labels)\n",
        "\n",
        "for i in returnABatch(df.reset_index(),2)  :\n",
        "  if i[1].shape[0] < 6:\n",
        "    print(len(i),len(i[1]))\n",
        "    print(i[0].shape)\n",
        "    print(i[1])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql7EHi_cMYYP",
        "colab_type": "text"
      },
      "source": [
        "### For Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dhi_DvKXMXYN",
        "colab_type": "text"
      },
      "source": [
        "def returnABatch1d(df,batch_size):\n",
        "  #returns a balanced label mri images\n",
        "  index_list = returnBatchIndices(df,batch_size)\n",
        "  #print(\"index list\",len(list(index_list)))\n",
        "  df2 = pd.get_dummies(df['label'], prefix = 'label')\n",
        "  df = pd.concat([df,df2],axis=1)\n",
        "  for j in index_list:\n",
        "    batch_images=[]\n",
        "    batch_labels=[]\n",
        "    #print(\"j\",j)\n",
        "    for i in j:\n",
        "      #print(\"i\",i)\n",
        "      label_list=[]\n",
        "      image = retrieveImage(list(df[df.index == i]['file_name'])[0])\n",
        "      transformed_image = image.reshape(512*512)\n",
        "      batch_images.append(transformed_image)\n",
        "      label_list.append(df[df.index == i]['label_1'].tolist()[0])\n",
        "      label_list.append(df[df.index == i]['label_2'].tolist()[0])\n",
        "      label_list.append(df[df.index == i]['label_3'].tolist()[0])\n",
        "      batch_labels.append(label_list)\n",
        "      #print(\"Batches :\",len(batch_images),len(batch_labels))\n",
        "\n",
        "    #from keras.utils import to_categorical\n",
        "    #batch_labels = to_categorical(batch_labels)\n",
        "    yield np.array(batch_images), np.array(batch_labels)\n",
        "\n",
        "for i in returnABatch1d(df.reset_index(),2)  :\n",
        "  if i[1].shape[0] < 6:\n",
        "    print(len(i),len(i[1]))\n",
        "    print(i[0].shape)\n",
        "    print(i[1])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFyXNbgckbCt",
        "colab_type": "text"
      },
      "source": [
        "#Model Building\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAFFed2pEX8W",
        "colab_type": "text"
      },
      "source": [
        "## CNN Approach using Tensorflow keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcguDqrmyuR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", input_shape=(512,512,3))\n",
        "            ,tf.keras.layers.MaxPooling2D(2,2)\n",
        "            ,tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\")\n",
        "            ,tf.keras.layers.MaxPooling2D(2,2)\n",
        "            ,tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\")\n",
        "            ,tf.keras.layers.MaxPooling2D(2,2)\n",
        "            ,tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\")\n",
        "            ,tf.keras.layers.MaxPooling2D(2,2)\n",
        "            ,tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\")\n",
        "            ,tf.keras.layers.MaxPooling2D(2,2)\n",
        "            #,tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\")\n",
        "            #,tf.keras.layers.MaxPooling2D(2,2)\n",
        "            ,tf.keras.layers.Flatten()\n",
        "            ,tf.keras.layers.Dropout(0.5)\n",
        "            ,tf.keras.layers.Dense(512, activation=\"relu\")\n",
        "            ,tf.keras.layers.Dense(3,activation=\"softmax\")            \n",
        "])\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\"\n",
        "              ,optimizer= \"adam\"\n",
        "              ,metrics=[\"accuracy\",\"Precision\",\"Recall\"])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoZHApFUtxgH",
        "colab_type": "text"
      },
      "source": [
        "img = plt.imread(\"/content/data/1/1.jpg\")\n",
        "plt.imshow(img,cmap=\"bone\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-AGrENCXpN1",
        "colab_type": "text"
      },
      "source": [
        "target = df_temp.pop('label')\n",
        "dataset = tf.data.Dataset.from_tensor_slices((df_temp.values, target.values))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecS_esHM67zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history=model.fit_generator(train_generator\n",
        "                  #,steps_per_epoch=286\n",
        "                  , epochs=2\n",
        "                  ,use_multiprocessing=True\n",
        "                  ,validation_data=validate_generator\n",
        "                  ,workers=8\n",
        "                  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBueyG7UzkVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('./final_model.h5', include_optimizer=True)\n",
        "from tensorflow.keras.models import load_model\n",
        "model2 = load_model('./final_model.h5')\n",
        "history2=model2.fit_generator(train_generator\n",
        "                  #,steps_per_epoch=286\n",
        "                  , epochs=2\n",
        "                  ,use_multiprocessing=True\n",
        "                  ,validation_data=validate_generator\n",
        "                  ,workers=8\n",
        "                  )\n",
        "\n",
        "result2 = model2.evaluate(test_generator)\n",
        "print(result2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ex2GT1x-6SG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = model.evaluate(test_generator)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uljl3NAf8Jos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history=model.fit_generator(validate_generator\n",
        "                  #,steps_per_epoch=286\n",
        "                  , epochs=2\n",
        "                  ,use_multiprocessing=True\n",
        "                  ,validation_data=test_generator\n",
        "                  ,workers=8\n",
        "                  )\n",
        "result = model.evaluate(test_generator)\n",
        "print(result)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJhyb__OadUy",
        "colab_type": "text"
      },
      "source": [
        "### Pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4srxIYwTagJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preTrain():\n",
        "  import os\n",
        "\n",
        "  from tensorflow.keras import layers\n",
        "  from tensorflow.keras import Model\n",
        "  !wget --no-check-certificate \\\n",
        "      https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "      -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "  local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "  pre_trained_model = InceptionV3(input_shape = (512,512,3), \n",
        "                                  include_top = False, \n",
        "                                  weights = None)\n",
        "\n",
        "  pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "  for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "  #print(pre_trained_model.summary())\n",
        "\n",
        "  last_layer = pre_trained_model.get_layer('mixed7')\n",
        "  print('last layer output shape: ', last_layer.output_shape)\n",
        "  last_output = last_layer.output\n",
        "\n",
        "  from tensorflow.keras.optimizers import RMSprop\n",
        "  x = layers.Conv2D(64, (3,3), activation=\"relu\")(last_output)\n",
        "  x = layers.MaxPooling2D(2,2)(x)\n",
        "  x = layers.Conv2D(64, (3,3), activation=\"relu\")(x)\n",
        "  x = layers.MaxPooling2D(2,2)(x)\n",
        "  # Flatten the output layer to 1 dimension\n",
        "  #x = layers.Flatten()(last_output)\n",
        "  x = layers.Flatten()(x)\n",
        "  # Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "  x = layers.Dense(512, activation='relu')(x)\n",
        "  # Add a dropout rate of 0.2\n",
        "  x = layers.Dropout(0.5)(x)                  \n",
        "  # Add a final sigmoid layer for classification\n",
        "  x = layers.Dense  (3, activation='sigmoid')(x)           \n",
        "\n",
        "  model = Model( pre_trained_model.input, x) \n",
        "  return model\n",
        "imageNet_model = preTrain()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlUhmzy2380C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imageNet_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxHeuBcA4TVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imageNet_model.compile(loss=\"categorical_crossentropy\"\n",
        "              ,optimizer= \"adam\"\n",
        "              ,metrics=[\"accuracy\",\"Recall\",\"Precision\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWUHrCKk4ZMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator, validate_generator, test_generator = getGenerators(32,(512,512))\n",
        "history=imageNet_model.fit_generator(train_generator\n",
        "                  #,steps_per_epoch=286\n",
        "                  , epochs=3\n",
        "                  ,use_multiprocessing=True\n",
        "                  ,validation_data=validate_generator\n",
        "                  #,workers=2\n",
        "                  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cIJzWiY4dkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = imageNet_model.evaluate(test_generator)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eusltMTwF9NZ",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression using Tensorflow Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb8bFUocuERf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "             tf.keras.layers.Flatten(input_shape=(512, 512,3))\n",
        "            ,tf.keras.layers.Dense(3, activation=\"softmax\")            \n",
        "])\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\"\n",
        "              ,optimizer= \"adam\"\n",
        "              ,metrics=[\"accuracy\",\"Recall\",\"Precision\"])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTbDTPvPNtRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history=model.fit_generator(train_generator\n",
        "                  #,steps_per_epoch=286\n",
        "                  , epochs=5\n",
        "                  ,use_multiprocessing=True\n",
        "                  ,validation_data=validate_generator\n",
        "                  ,workers=2\n",
        "                  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDTHRX8Q7_2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = model.evaluate(test_generator)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V_RPsdvE4dP",
        "colab_type": "text"
      },
      "source": [
        "batch_size = 64\n",
        "steps_per_epoch = round(df.groupby(\"label\").agg(\"count\").reset_index()['pid'].max()/batch_size)\n",
        "\n",
        "print(\"Total Training Dataset : \", df.shape[0])\n",
        "print(\"Batch Size : \", batch_size)\n",
        "print(\"Steps per epoch : \", steps_per_epoch)\n",
        "print(\"Test Datasize shape : \", df_test.shape[0])\n",
        "\n",
        "history=model.fit_generator(returnABatch1d(df,batch_size)\n",
        "                  ,steps_per_epoch=steps_per_epoch\n",
        "                  , epochs=5\n",
        "                  )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_FIgewtHwKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qfFq4-MXHXs",
        "colab_type": "text"
      },
      "source": [
        "# Model Testing\n",
        "* is the model bias for 256 size images ?\n",
        "* is there any imbalance in 256 size images ?\n",
        "* converting 512x512 to 256x256 size would definitely speed up the process but would it impact the accuracy ?\n",
        "* is the model has better accuracy for any type of tumor class? (as we have imbalanced set ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym6uQGG8gydZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFTO4bLSGRBk",
        "colab_type": "text"
      },
      "source": [
        "# Observations / Lesson Learnt:\n",
        "\n",
        "* Iteration 1:\n",
        "  * CNN of 512x512 took half an hour even on TPU\n",
        "  * more and more convolution layer decreases the neurons required for training( duh!!!) and hence the batch size can be increased.\n",
        "  * testing result was 49%. Not Acceptable.\n",
        "\n",
        "* Iteration 2:\n",
        "  * tried PCA but realized transformation is not suited for convolution\n",
        "  * tried to use imagegenerator by converting the numpy to image (jpg) file. But found that numpy to image was not successfull.\n",
        "\n",
        "* Iteration 3:\n",
        "  * experimented with ImageGenerator for training, validation and testing\n",
        "  * time is still a worry for CNN approach; it is 20 mins\n",
        "  * though it is fast for the logistic regression the epochs are not helping (epoch = 5)\n",
        "\n",
        "\n",
        "* Iteration 4:\n",
        "  * experimented with different CNN layers ( basically added one more layer to make shrink the image size to 6x6 but 14x14 was quicker and gave better result)\n",
        "  * average time per epoch is 20 min and 5 epochs gave 89% test accuracy with CNN approach\n",
        "  * deviation in the epoch accuracy indicates that few more epoch can reach upto 90 - 93% which way ahead of last finding during capstone submission (54%).[validation accuracy has also increased so far and hence predicting the accuracy to go beyond 90%]\n",
        "  * imagenet transfer learing takes 1 hour to complete one epoch and for one epoch it gives accuracy around 45%\n",
        "  * 3 epochs on imagenet with 512x512x3 image with 2 convolution at the end with dense network post that gave 90% training accuracy, 65% validation and testing result. Clearly, there is overfit.\n",
        "  * shrinking the size by 256x256 or 150x150 (as per imagenet assumption on input), drastically reduces the epoch time upto 5 min but the accuracy do not improve even for 5 epochs. Loss decreases but there is no change in the accuracy or accuracy decreases.\n",
        "  * till now, it leaves with no additional lesson learnt apart from few experimental observations. i.e. in the last capstone submission, i had CNN and imagenet experiment. but this time different CNN gave a better result and imagenet is yet to match the outcome of CNN. Only new thing learnt is that simplest conv2d (3x3) with max pooling can give better result.\n",
        "  * as part of new learning , I have :\n",
        "    * tf eager execution, instead of graph based as in last submission\n",
        "    * image generator to simplify code, augment the images and to reshape( not recommended).\n",
        "    * keras way of working with transfer learning\n",
        "    * numpy to image save\n",
        "    * experimenting with workers and parallel processing at \"fit\" and \"fit_generator\".\n",
        "    * couple of experiments were not possible if TPU and colab was not arround.\n",
        "    * bokeh experiments with images.\n",
        "    * automating data load operation through linux commands (wget, unzipping, creation and deletion folders, moving files, listing files)\n",
        "\n",
        "* Iteration 5:\n",
        "  * Saving models:\n",
        "    * I guess below approach is good:\n",
        "      * while(1):\n",
        "          * model.fit()\n",
        "          * model.save('./final_model.h5', include_optimizer=True)\n",
        "\n",
        "* Iteration 6:\n",
        "  * Simple LR has too many loss\n",
        "  * NN also has high loss and hence low accuracy \n",
        "  * NN has limitation number of neurons with which python crashes if the initial neuron shape crosses 8K."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iThtN8-UQc4Y",
        "colab_type": "text"
      },
      "source": [
        "# To Do\n",
        "* Batch normalization for both CNN and LR\n",
        "* dropout between each dense layer\n",
        "* is LR with PCA ( n = say 10K) equal to NN with cone structure ?\n",
        "  * as in, cone structure (decreasing stacked NN layer neurons) reduces the feature vector at each layer so is this a parallel approach to PCA ?\n",
        "\n",
        "* NN Experiments:\n",
        "  * adding addtional CNN layer to make the last dimention as 14x14 or 6x6\n",
        "      * 6x6 took additional time for one epoch and also took addional epochs to reach the accuracy as that of 14x14.\n",
        "      \n",
        "  * PCA and LR:\n",
        "    * 1 million (half of flattened layer) PCA dimention\n",
        "    * 50K PCA dimention\n",
        "    * 10K PCA dimention\n",
        "    * 5k\n",
        "    * 1K\n",
        "    * 512\n",
        "    * 256\n",
        "  * NN layers\n",
        "    * 100K, 50K, 25K, 12K, 6K, 3K, 1K, 512, 256, 128, 64, 32, 16, 8\n",
        "      * batch normalization\n",
        "      * drop outs\n",
        "\n",
        "* Preprocessing:\n",
        "  * skull removal through clustering\n",
        "  * image generator to reduce the size to 256x256\n",
        "\n",
        "\n",
        "* transfer learning\n",
        "* image segmentation\n",
        "  * try with only window of image with tumor for accuracy\n",
        "  * how is image segmentation actually done\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB0oEZYiGzJQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "cb74f3d7-c79b-408a-a579-dc1ee97b0d1d"
      },
      "source": [
        "def imageflatdf():\n",
        "  imageflatlist=[]\n",
        "  for d in os.listdir( \"training_data/\"):\n",
        "    for f in os.listdir(\"training_data/\"+d+\"/\"):\n",
        "      #plt.imshow(plt.imread(\"training_data/1/\"+f))\n",
        "      #print(plt.imread(\"training_data/1/\"+f).reshape(1,-1).shape)\n",
        "      image_array = plt.imread(\"training_data/\"+d+\"/\"+f)\n",
        "      image_array = image_array/image_array.max()\n",
        "      if image_array.shape[0] == 512:\n",
        "        imageflatlist.append((image_array.reshape(-1),d))\n",
        "      else:\n",
        "        image_array = np.pad(image_array,(512 - image_array.shape[0])//2,'constant',constant_values=0)\n",
        "        imageflatlist.append((image_array.reshape(-1),d)) \n",
        "      #break\n",
        "  df = pd.DataFrame(imageflatlist,columns=['image_array','label'])\n",
        "  return df\n",
        "\n",
        "df_flat = imageflatdf()\n",
        "df_flat.sample(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_array</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1339</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>929</th>\n",
              "      <td>[0.0, 0.0, 0.00392156862745098, 0.007843137254...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2124</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1768</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1560</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>851</th>\n",
              "      <td>[0.0, 0.0, 0.00392156862745098, 0.007843137254...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1978</th>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            image_array label\n",
              "1339  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     2\n",
              "929   [0.0, 0.0, 0.00392156862745098, 0.007843137254...     3\n",
              "2124  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     2\n",
              "1768  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     2\n",
              "19    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     1\n",
              "629   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003...     3\n",
              "1560  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     2\n",
              "494   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     1\n",
              "851   [0.0, 0.0, 0.00392156862745098, 0.007843137254...     3\n",
              "1978  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007...     2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv50XhoNSkiT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "f8c609c8-ff1a-4d68-a288-89515fa537d7"
      },
      "source": [
        "df_flat.groupby(\"label\").agg(\"count\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_array</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>691</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       image_array\n",
              "label             \n",
              "1              527\n",
              "2             1051\n",
              "3              691"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SXp2d-O0qmm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "377851c5-7598-4725-96f5-16411080f05c"
      },
      "source": [
        "df_flat.image_array[0].shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(262144,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDZHQnZy0Rea",
        "colab_type": "text"
      },
      "source": [
        "#PCA + LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHxm_SkUzAWv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "outputId": "deb722ad-5331-442f-db79-e2a70ed3f2fd"
      },
      "source": [
        "def doLR(df):\n",
        "\n",
        "  #df['label'] = pd.Categorical(df['label'])\n",
        "  df['label'] = df.label.astype(np.int)\n",
        "\n",
        "  df_test = df.sample(frac=0.2)\n",
        "  df_train = df.drop(df_test.index)\n",
        "  \n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Dense(1, input_shape=[262144], activation=\"softmax\") \n",
        "            ])\n",
        "  model.compile(loss=\"categorical_crossentropy\"\n",
        "              ,optimizer= \"adam\"\n",
        "              ,metrics=[\"accuracy\",\"Recall\",\"Precision\"])\n",
        "  print(model.summary())\n",
        "\n",
        "\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((df_train.image_array, df_train.label))\n",
        "  \n",
        "  for feat, targ in dataset.take(5):\n",
        "    print ('Features: {}, Target: {}'.format(feat, targ))\n",
        "\n",
        "  train_dataset = dataset.batch(50)\n",
        "  #model.fit(dataset)\n",
        "  model.fit_generator(train_dataset,epochs=10)\n",
        "  \n",
        "  dataset = tf.data.Dataset.from_tensor_slices((df_test.image_array, df_test.label))\n",
        "  test_dataset = dataset.batch(50)\n",
        "  return model.evaluate(test_dataset)\n",
        "\n",
        "doLR(df_flat.copy())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 1)                 262145    \n",
            "=================================================================\n",
            "Total params: 262,145\n",
            "Trainable params: 262,145\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Features: [0. 0. 0. ... 0. 0. 0.], Target: 1\n",
            "Features: [0. 0. 0. ... 0. 0. 0.], Target: 1\n",
            "Features: [0.         0.         0.         ... 0.00784314 0.00392157 0.        ], Target: 1\n",
            "Features: [0. 0. 0. ... 0. 0. 0.], Target: 1\n",
            "Features: [0. 0. 0. ... 0. 0. 0.], Target: 1\n",
            "Epoch 1/10\n",
            "37/37 [==============================] - 5s 137ms/step - loss: 2.4848e-07 - accuracy: 0.2298 - Recall: 1.0000 - Precision: 1.0000\n",
            "Epoch 2/10\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 2.4848e-07 - accuracy: 0.2298 - Recall: 1.0000 - Precision: 1.0000\n",
            "Epoch 3/10\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 2.4848e-07 - accuracy: 0.2298 - Recall: 1.0000 - Precision: 1.0000\n",
            "Epoch 4/10\n",
            "37/37 [==============================] - 5s 134ms/step - loss: 2.4848e-07 - accuracy: 0.2298 - Recall: 1.0000 - Precision: 1.0000\n",
            "Epoch 5/10\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 2.4848e-07 - accuracy: 0.2298 - Recall: 1.0000 - Precision: 1.0000\n",
            "Epoch 6/10\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 2.4848e-07 - accuracy: 0.2298 - Recall: 1.0000 - Precision: 1.0000\n",
            "Epoch 7/10\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 2.4848e-07 - accuracy: 0.2298 - Recall: 1.0000 - Precision: 1.0000\n",
            "Epoch 8/10\n",
            "37/37 [==============================] - 5s 135ms/step - loss: 2.4848e-07 - accuracy: 0.2298 - Recall: 1.0000 - Precision: 1.0000\n",
            "Epoch 9/10\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 2.4848e-07 - accuracy: 0.2298 - Recall: 1.0000 - Precision: 1.0000\n",
            "Epoch 10/10\n",
            "37/37 [==============================] - 5s 136ms/step - loss: 2.4848e-07 - accuracy: 0.2298 - Recall: 1.0000 - Precision: 1.0000\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 0.0000e+00 - accuracy: 0.2423 - Recall: 1.0000 - Precision: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.24229075, 1.0, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJw1KmYsH_Pj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "outputId": "e19e3a3b-875c-4251-a6c7-a1570cd04eff"
      },
      "source": [
        "def doNN(df):\n",
        "\n",
        "  #df['label'] = pd.Categorical(df['label'])\n",
        "  df['label'] = df.label.astype(np.int)\n",
        "\n",
        "  df_test = df.sample(frac=0.2)\n",
        "  df_train = df.drop(df_test.index)\n",
        "  \n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Dense(4098, input_shape=[262144], activation=\"relu\") \n",
        "            ,tf.keras.layers.Dropout(0.5)\n",
        "            #,tf.keras.layers.Dense(2048, activation=\"relu\") \n",
        "            #,tf.keras.layers.Dropout(0.5)\n",
        "            ,tf.keras.layers.Dense(1024, activation=\"relu\") \n",
        "            ,tf.keras.layers.Dropout(0.5)\n",
        "            #,tf.keras.layers.Dense(512, activation=\"relu\") \n",
        "            #,tf.keras.layers.Dropout(0.5)\n",
        "            ,tf.keras.layers.Dense(128, activation=\"relu\") \n",
        "            ,tf.keras.layers.Dropout(0.5)\n",
        "            ,tf.keras.layers.Dense(1, activation=\"softmax\") \n",
        "            ])\n",
        "  model.compile(loss=\"categorical_crossentropy\"\n",
        "              ,optimizer= \"adam\"\n",
        "              ,metrics=[\"accuracy\",\"Recall\",\"Precision\"])\n",
        "  print(model.summary())\n",
        "\n",
        "\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((df_train.image_array, df_train.label))\n",
        "  \n",
        "  for feat, targ in dataset.take(5):\n",
        "    print ('Features: {}, Target: {}'.format(feat, targ))\n",
        "\n",
        "  train_dataset = dataset.batch(50)\n",
        "  #model.fit(dataset)\n",
        "  model.fit_generator(train_dataset,epochs=5)\n",
        "  \n",
        "  dataset = tf.data.Dataset.from_tensor_slices((df_test.image_array, df_test.label))\n",
        "  test_dataset = dataset.batch(50)\n",
        "  return model.evaluate(test_dataset)\n",
        "\n",
        "doNN(df_flat.copy())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 4098)              1074270210\n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4098)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2048)              8394752   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,085,353,731\n",
            "Trainable params: 1,085,353,731\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Features: [0.         0.         0.         ... 0.00392157 0.00392157 0.00392157], Target: 1\n",
            "Features: [0. 0. 0. ... 0. 0. 0.], Target: 1\n",
            "Features: [0. 0. 0. ... 0. 0. 0.], Target: 1\n",
            "Features: [0.         0.         0.         ... 0.00784314 0.00392157 0.        ], Target: 1\n",
            "Features: [0. 0. 0. ... 0. 0. 0.], Target: 1\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/ops/math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "37/37 [==============================] - 46s 1s/step - loss: 2.4777e-07 - accuracy: 0.2264 - Recall: 1.0000 - Precision: 1.0000\n",
            "Epoch 2/5\n",
            "37/37 [==============================] - 45s 1s/step - loss: 2.4777e-07 - accuracy: 0.2264 - Recall: 1.0000 - Precision: 1.0000\n",
            "Epoch 3/5\n",
            "37/37 [==============================] - 44s 1s/step - loss: 2.4777e-07 - accuracy: 0.2264 - Recall: 1.0000 - Precision: 1.0000\n",
            "Epoch 4/5\n",
            "37/37 [==============================] - 44s 1s/step - loss: 2.4777e-07 - accuracy: 0.2264 - Recall: 1.0000 - Precision: 1.0000\n",
            "Epoch 5/5\n",
            "37/37 [==============================] - 44s 1s/step - loss: 2.4777e-07 - accuracy: 0.2264 - Recall: 1.0000 - Precision: 1.0000\n",
            "10/10 [==============================] - 4s 363ms/step - loss: 0.0000e+00 - accuracy: 0.2555 - Recall: 1.0000 - Precision: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.2555066, 1.0, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmFSRH0IVPc7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "outputId": "35b32e80-e8d1-49e5-d2eb-f63015e2fdfb"
      },
      "source": [
        "def doPCANN(df):\n",
        "\n",
        "  #df['label'] = pd.Categorical(df['label'])\n",
        "  df['label'] = df.label.astype(np.int)\n",
        "  \n",
        "  from sklearn.decomposition import PCA\n",
        "  pca = PCA(n_components=1024,whiten=True)\n",
        "  pca.fit(df.image_array.to_list())\n",
        "  df[\"image_array_pca\"] = df.image_array.apply(lambda x: pca.transform(x.reshape(1, -1))[0])\n",
        "\n",
        "  df_test = df.sample(frac=0.2)\n",
        "  df_train = df.drop(df_test.index)\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Dense(4098, input_shape=[1024], activation=\"relu\") \n",
        "            ,tf.keras.layers.Dropout(0.5)\n",
        "            #,tf.keras.layers.Dense(2048, activation=\"relu\") \n",
        "            #,tf.keras.layers.Dropout(0.5)\n",
        "            ,tf.keras.layers.Dense(1024, activation=\"relu\") \n",
        "            ,tf.keras.layers.Dropout(0.5)\n",
        "            #,tf.keras.layers.Dense(512, activation=\"relu\") \n",
        "            #,tf.keras.layers.Dropout(0.5)\n",
        "            ,tf.keras.layers.Dense(128, activation=\"relu\") \n",
        "            ,tf.keras.layers.Dropout(0.5)\n",
        "            ,tf.keras.layers.Dense(1, activation=\"softmax\") \n",
        "            ])\n",
        "  model.compile(loss=\"categorical_crossentropy\"\n",
        "              ,optimizer= \"adam\"\n",
        "              ,metrics=[\"accuracy\",\"Recall\",\"Precision\"])\n",
        "  print(model.summary())\n",
        "\n",
        "\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((df_train.image_array_pca, df_train.label))\n",
        "  \n",
        "  for feat, targ in dataset.take(5):\n",
        "    print ('Features: {}, Target: {}'.format(feat, targ))\n",
        "\n",
        "  train_dataset = dataset.batch(50)\n",
        "  #model.fit(dataset)\n",
        "  model.fit_generator(train_dataset,epochs=5)\n",
        "  \n",
        "  dataset = tf.data.Dataset.from_tensor_slices((df_test.image_array_pca, df_test.label))\n",
        "  test_dataset = dataset.batch(50)\n",
        "  return model.evaluate(test_dataset)\n",
        "\n",
        "doPCANN(df_flat.copy())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 4098)              4200450   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4098)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              4197376   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 8,529,155\n",
            "Trainable params: 8,529,155\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Features: [-1.30768738 -0.59999449  0.52114848 ... -0.2281648  -0.88563947\n",
            " -1.23152605], Target: 1\n",
            "Features: [ 1.43295413 -0.37642281  0.01758194 ... -1.90683203 -0.47763814\n",
            "  0.02879288], Target: 1\n",
            "Features: [ 0.0974554   1.60790667  1.12338619 ... -0.19902083  0.74932525\n",
            "  0.78126301], Target: 1\n",
            "Features: [-0.18877913  1.05615543 -0.40680465 ... -0.02484835 -1.46535759\n",
            "  0.42839942], Target: 1\n",
            "Features: [-1.22616177 -0.39608065  1.75062171 ...  1.03743935 -0.89092385\n",
            "  0.34447152], Target: 1\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/ops/math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "37/37 [==============================] - 2s 56ms/step - loss: 2.4725e-07 - accuracy: 0.2298 - Recall: 1.0000 - Precision: 1.0000\n",
            "Epoch 2/5\n",
            "37/37 [==============================] - 2s 45ms/step - loss: 2.4725e-07 - accuracy: 0.2298 - Recall: 1.0000 - Precision: 1.0000\n",
            "Epoch 3/5\n",
            "37/37 [==============================] - 2s 45ms/step - loss: 2.4725e-07 - accuracy: 0.2298 - Recall: 1.0000 - Precision: 1.0000\n",
            "Epoch 4/5\n",
            "37/37 [==============================] - 2s 44ms/step - loss: 2.4725e-07 - accuracy: 0.2298 - Recall: 1.0000 - Precision: 1.0000\n",
            "Epoch 5/5\n",
            "37/37 [==============================] - 2s 45ms/step - loss: 2.4725e-07 - accuracy: 0.2298 - Recall: 1.0000 - Precision: 1.0000\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0000e+00 - accuracy: 0.2423 - Recall: 1.0000 - Precision: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.24229075, 1.0, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjzPG58tUsC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def doPCA(df):\n",
        "  import numpy as np\n",
        "  from sklearn.decomposition import PCA\n",
        "  pca = PCA(n_components=2,whiten=True)\n",
        "\n",
        "  print(np.array(df.image_array.to_list()).shape)\n",
        "  pca.fit(df.image_array.to_list())\n",
        "  #pca.transform(image[0].reshape((1,-1)))\n",
        "  #return [pca.transform(image) for image in df.image_array.to_list() if image.shape[0] == 262144]\n",
        "  df['x'] = df.image_array.apply(lambda x: pca.transform(x.reshape(1, -1))[0][0] if x.shape[0]== 262144 else 0)\n",
        "  df['y'] = df.image_array.apply(lambda x: pca.transform(x.reshape(1, -1))[0][1] if x.shape[0]== 262144 else 0)\n",
        "\n",
        "  return df\n",
        "\n",
        "x_y = doPCA(df_flat.copy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL06EyYxKWab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_y.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qy4t7upMSQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_y['label'] = x_y.label.astype(np.int)\n",
        "x_y.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce37jsZKvMFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotp(x_y):\n",
        "  plt.scatter(x_y['x'],x_y['y'],c=x_y['label'])\n",
        "  plt.show()\n",
        "\n",
        "plotp(x_y[x_y.label == 1])\n",
        "plotp(x_y[x_y.label == 2])\n",
        "plotp(x_y[x_y.label == 3])\n",
        "plotp(x_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1YBCCWqv3l1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(plt.imread(\"training_data/1/1.jpg\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk3PzIHrwjJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_image = plt.imread(\"training_data/1/1.jpg\").copy()\n",
        "ma = temp_image.max()*.8\n",
        "print(ma)\n",
        "temp_image[temp_image > ma]= 0\n",
        "plt.imshow(temp_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mytrMAChxR6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def doCluster(df):\n",
        "  from sklearn import cluster\n",
        "  k_means = cluster.KMeans(n_clusters=2, n_init=4)\n",
        "  k_means.fit(df.image_array.to_list())\n",
        "\n",
        "  return df\n",
        "\n",
        "tt = doCluster(df_flat.copy())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}